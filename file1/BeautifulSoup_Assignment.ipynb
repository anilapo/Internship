{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50ad8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Title  Rating  Year\n",
      "0                     Ship of Theseus     8.0  2012\n",
      "1                              Iruvar     8.4  1997\n",
      "2                     Kaagaz Ke Phool     7.8  1959\n",
      "3   Lagaan: Once Upon a Time in India     8.1  2001\n",
      "4                     Pather Panchali     8.2  1955\n",
      "..                                ...     ...   ...\n",
      "95                        Apur Sansar     8.4  1959\n",
      "96                        Kanchivaram     8.2  2008\n",
      "97                    Monsoon Wedding     7.3  2001\n",
      "98                              Black     8.1  2005\n",
      "99                            Deewaar     8.0  1975\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.imdb.com/list/ls056092300/\"\n",
    "\n",
    "def scrape_imdb_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    movies = []\n",
    "    movie_list = soup.find_all(\"div\", class_=\"lister-item-content\")\n",
    "\n",
    "    for movie in movie_list:\n",
    "        title = movie.find(\"a\").text\n",
    "        rating = float(movie.find(\"span\", class_=\"ipl-rating-star__rating\").text)\n",
    "        year_str = movie.find(\"span\", class_=\"lister-item-year\").text.strip('()')\n",
    "        year = int(''.join(filter(str.isdigit, year_str)))\n",
    "\n",
    "        movies.append({\"Title\": title, \"Rating\": rating, \"Year\": year})\n",
    "\n",
    "    return movies\n",
    "\n",
    "def create_dataframe(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    imdb_data = scrape_imdb_data(URL)\n",
    "    imdb_df = create_dataframe(imdb_data)\n",
    "\n",
    "    print(imdb_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2905e38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://peachmode.com/search?q=bags\"\n",
    "\n",
    "def scrape_peachmode_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    products = []\n",
    "    product_list = soup.find_all(\"div\", class_=\"product-item\")\n",
    "\n",
    "    for product in product_list:\n",
    "        name = product.find(\"h2\", class_=\"product-name\").text.strip()\n",
    "        price = product.find(\"span\", class_=\"price\").text.strip()\n",
    "        discount = product.find(\"span\", class_=\"discount\").text.strip()\n",
    "\n",
    "        products.append({\"Product Name\": name, \"Price\": price, \"Discount\": discount})\n",
    "\n",
    "    return products\n",
    "\n",
    "def create_dataframe(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    peachmode_data = scrape_peachmode_data(URL)\n",
    "    peachmode_df = create_dataframe(peachmode_data)\n",
    "\n",
    "    print(peachmode_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ec2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://peachmode.com/search?q=bags\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "products = soup.find_all(\"div\", class_=\"product-item\")\n",
    "\n",
    "for product in products:\n",
    "    name = product.find(\"h2\", class_=\"product-name\").text.strip()\n",
    "    price = product.find(\"span\", class_=\"price\").text.strip()\n",
    "    discount = product.find(\"span\", class_=\"discount\").text.strip() if product.find(\"span\", class_=\"discount\") else \"No Discount\"\n",
    "\n",
    "    print(\"Product Name:\", name)\n",
    "    print(\"Price:\", price)\n",
    "    print(\"Discount:\", discount)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f16e32df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with class 'table' not found.\n",
      "No data found. Please check the URL or website structure.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "\n",
    "def scrape_odi_rankings(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all(\"table\", class_=\"table\")\n",
    "    if len(tables) == 0:\n",
    "        print(\"Table with class 'table' not found.\")\n",
    "        return []\n",
    "\n",
    "    teams_data = []\n",
    "    teams_list = tables[0].find(\"tbody\").find_all(\"tr\")[:10]\n",
    "\n",
    "    for team in teams_list:\n",
    "        name = team.find(\"span\", class_=\"u-hide-phablet\").text.strip()\n",
    "        matches = int(team.find_all(\"td\")[2].text)\n",
    "        points = int(team.find_all(\"td\")[3].text)\n",
    "        rating = int(team.find_all(\"td\")[4].text)\n",
    "\n",
    "        teams_data.append({\"Team\": name, \"Matches\": matches, \"Points\": points, \"Rating\": rating})\n",
    "\n",
    "    return teams_data\n",
    "\n",
    "def create_dataframe(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    odi_rankings_data = scrape_odi_rankings(URL)\n",
    "    \n",
    "    if not odi_rankings_data:\n",
    "        print(\"No data found. Please check the URL or website structure.\")\n",
    "    else:\n",
    "        odi_rankings_df = create_dataframe(odi_rankings_data)\n",
    "        print(odi_rankings_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "993a0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa7492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Teams:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/test\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "teams = soup.find_all(\"tr\", class_=\"table-body\")[:10]  # Extract top 10 teams\n",
    "\n",
    "print(\"Top 10 ODI Teams:\")\n",
    "for team in teams:\n",
    "    name = team.find(\"span\", class_=\"u-hide-phablet\").text.strip()\n",
    "    matches = team.find_all(\"td\")[2].text.strip()\n",
    "    points = team.find_all(\"td\")[3].text.strip()\n",
    "    rating = team.find_all(\"td\")[4].text.strip()\n",
    "\n",
    "    print(f\"Team: {name}, Matches: {matches}, Points: {points}, Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05edaa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Batsmen:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/test\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "players = soup.find_all(\"tr\", class_=\"table-body\")[0:10]  # Extract top 10 players\n",
    "\n",
    "print(\"Top 10 ODI Batsmen:\")\n",
    "for player in players:\n",
    "    name = player.find(\"td\", class_=\"table-body__cell name\").text.strip()\n",
    "    team = player.find(\"span\", class_=\"table-body__logo-text\").text.strip()\n",
    "    rating = player.find(\"td\", class_=\"table-body__cell u-text-right rating\").text.strip()\n",
    "\n",
    "    print(f\"Name: {name}, Team: {team}, Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38e3fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Bowlers:\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/bowling/mens/odi\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "players = soup.find_all(\"tr\", class_=\"table-body\")[0:10]  # Extract top 10 players\n",
    "\n",
    "print(\"Top 10 ODI Bowlers:\")\n",
    "for player in players:\n",
    "    name = player.find(\"td\", class_=\"table-body__cell name\").text.strip()\n",
    "    team = player.find(\"span\", class_=\"table-body__logo-text\").text.strip()\n",
    "    wickets = player.find(\"td\", class_=\"table-body__cell u-text-right wkts\").text.strip()\n",
    "    economy = player.find(\"td\", class_=\"table-body__cell u-text-right economy\").text.strip()[1:-1]  # Remove brackets\n",
    "    average = player.find(\"td\", class_=\"table-body__cell u-text-right avg\").text.strip()\n",
    "    strike_rate = player.find(\"td\", class_=\"table-body__cell u-text-right sr\").text.strip()\n",
    "    rating = player.find(\"td\", class_=\"table-body__cell u-text-right rating\").text.strip()\n",
    "\n",
    "    print(f\"Name: {name}, Team: {team}, Wickets: {wickets}, Economy: {economy}, Average: {average}, Strike Rate: {strike_rate}, Rating: {rating}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74f2895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.patreon.com/coreyms\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "posts = soup.find_all(\"div\", class_=\"post-card\")\n",
    "\n",
    "for post in posts:\n",
    "    heading = post.find(\"h3\", class_=\"post-card__title\").text.strip()\n",
    "    date = post.find(\"time\", class_=\"post-card__published-date\").text.strip()\n",
    "    content = post.find(\"div\", class_=\"post-card__excerpt\").text.strip()\n",
    "\n",
    "    youtube_link = post.find(\"a\", class_=\"post-card__youtube-link\")\n",
    "    if youtube_link:\n",
    "        youtube_url = youtube_link[\"href\"]\n",
    "        # You can scrape additional details from the YouTube video link if needed\n",
    "\n",
    "    likes = post.find(\"span\", class_=\"post-card__like-count\").text.strip()\n",
    "\n",
    "    print(f\"Heading: {heading}\")\n",
    "    print(f\"Date: {date}\")\n",
    "    print(f\"Content: {content}\")\n",
    "    if youtube_link:\n",
    "        print(f\"YouTube Video Link: {youtube_url}\")\n",
    "    print(f\"Likes: {likes}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6209b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "LOCALITIES = [\"Indira Nagar\", \"Jayanagar\", \"Rajaji Nagar\"]\n",
    "\n",
    "def fetch_house_details(locality):\n",
    "    url = f\"https://www.nobroker.in/{locality}/residential-property\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    houses = soup.select(\".listing-container\")\n",
    "    for container in houses[:3]:  # Fetch maximum three properties\n",
    "        title = container.find(\"h2\", class_=\"listing-title\").text.strip()\n",
    "        location = container.find(\"p\", class_=\"location\").text.strip()\n",
    "        area = int(re.search(r\"\\d+ sqft\", container.find(\"p\", class_=\"area\").text.lower()).group(0)[len('sqft'):])\n",
    "        emi = float(container.find(\"strong\", text=re.compile(\"EMI\")).parent.next_element.text.strip())\n",
    "        price = int(container.find(\"strong\", text=re.compile(\"₹\\d+\\,\\d{3}\")).parent.next_sibling.text.strip().split(\"/\")[-1][:-1])\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Title: {title}\\nLocation: {location}\\nArea: {area} sq ft\\nEMI: Rs. {emi:,.2f}\\nPrice: Rs. {price:,.0f}\")\n",
    "\n",
    "for loc in LOCALITIES:\n",
    "    fetch_house_details(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90c0d7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-black-pyjamas-581562-1707292627-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-red-boyfriend-t-shirt-170465-1658918677-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirt-106-1701423878-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirts-1094-1708612740-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-white-t-shirt-105-1702967985-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/sage-green-casual-cotton-trouser-340543-1663661829-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/dark-olive-casual-cotton-trouser-330854-1663662028-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/desert-beige-casual-cotton-trouser-330853-1663661915-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-sky-blue-cotton-jogger-pants-330846-1664197182-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/melting-leaf-baseball-cap-405263-1672908030-1.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.bewakoof.com/bestseller?sort=popular\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "products = soup.find_all(\"div\", class_=\"productCardBox\")\n",
    "\n",
    "for product in products[:10]:  # Extract details of the first 10 products\n",
    "    name_element = product.find(\"h3\", class_=\"product-title\")\n",
    "    price_element = product.find(\"span\", class_=\"product-price\")\n",
    "    image_element = product.find(\"img\")\n",
    "\n",
    "    if name_element:\n",
    "        name = name_element.text.strip()\n",
    "    else:\n",
    "        name = \"Not Available\"\n",
    "\n",
    "    if price_element:\n",
    "        price = price_element.text.strip()\n",
    "    else:\n",
    "        price = \"Not Available\"\n",
    "\n",
    "    if image_element:\n",
    "        image_url = image_element[\"src\"]\n",
    "    else:\n",
    "        image_url = \"Not Available\"\n",
    "\n",
    "    print(\"Product Name:\", name)\n",
    "    print(\"Price:\", price)\n",
    "    print(\"Image URL:\", image_url)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244e14b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-aop-regular-pyjama-604946-1702644020-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-black-pyjamas-581562-1707292627-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/jet-black-vest-210687-1659522825-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-batman-outline-logo-t-shirt-283889-1701423873-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-black-boyfriend-t-shirt-103943-1655747735-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-white-marvel-printed-t-shirt-390747-1705996158-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-white-t-shirt-1093-1708356232-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirts-1094-1708612740-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirt-106-1701423878-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-red-boyfriend-t-shirt-170465-1658918677-1.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "affe51a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-black-pyjamas-581562-1707292627-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/women-s-red-boyfriend-t-shirt-170465-1658918677-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirt-106-1701423878-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-black-t-shirts-1094-1708612740-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-white-t-shirt-105-1702967985-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/sage-green-casual-cotton-trouser-340543-1663661829-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/dark-olive-casual-cotton-trouser-330854-1663662028-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/desert-beige-casual-cotton-trouser-330853-1663661915-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/men-s-sky-blue-cotton-jogger-pants-330846-1664197182-1.jpg\n",
      "\n",
      "\n",
      "Product Name: Not Available\n",
      "Price: Not Available\n",
      "Image URL: https://images.bewakoof.com/t640/melting-leaf-baseball-cap-405263-1672908030-1.jpg\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.bewakoof.com/bestseller?sort=popular\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "products = soup.find_all(\"div\", class_=\"productCardBox\")\n",
    "\n",
    "for product in products[:10]:  # Extract details of the first 10 products\n",
    "    name_element = product.find(\"h3\", class_=\"product-title\")\n",
    "    price_element = product.find(\"span\", class_=\"product-discountPrice\")\n",
    "\n",
    "    name = name_element.text.strip() if name_element else \"Not Available\"\n",
    "    price = price_element.text.strip() if price_element else \"Not Available\"\n",
    "\n",
    "    image_element = product.find(\"img\")\n",
    "    image_url = image_element[\"src\"] if image_element else \"Not Available\"\n",
    "\n",
    "    print(\"Product Name:\", name)\n",
    "    print(\"Price:\", price)\n",
    "    print(\"Image URL:\", image_url)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a45faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://peachmode.com/search?q=bags\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "products = soup.find_all(\"div\", class_=\"product-item\")\n",
    "\n",
    "for product in products:\n",
    "    name_element = product.find(\"h2\", class_=\"product-name\")\n",
    "    price_element = product.find(\"span\", class_=\"price\")\n",
    "    discount_element = product.find(\"span\", class_=\"discount\")\n",
    "\n",
    "    name = name_element.text.strip() if name_element else \"Not Available\"\n",
    "    price = price_element.text.strip() if price_element else \"Not Available\"\n",
    "    discount = discount_element.text.strip() if discount_element else \"No Discount\"\n",
    "\n",
    "    print(\"Product Name:\", name)\n",
    "    print(\"Price:\", price)\n",
    "    print(\"Discount:\", discount)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3a881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
